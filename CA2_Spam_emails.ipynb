{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4p_DvtT7sOIr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjKF0nIMwz8_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_Dictionary(root_dir):\n",
    "  #initialize an empty to list to hold the words\n",
    "  all_words = []\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "  for mail in emails:\n",
    "    with open(mail) as m:\n",
    "      for line in m:\n",
    "        #split each line into words\n",
    "        words = line.split()\n",
    "        #append the words to the all_words list\n",
    "        all_words += words\n",
    "  #create dictionary to count the occurences of each word\n",
    "  dictionary = Counter(all_words)\n",
    "  #have a list of words to remove\n",
    "  list_to_remove = list(dictionary)\n",
    "\n",
    "  #remove non alphabetic words and single character words from dictionary\n",
    "  for item in list_to_remove:\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "  #select 3000 the most common words  \n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVW5xNlyOFc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  # Initialize features_matrix\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "  # Initialize array for train_labels\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "  # Loop through each file in the directory\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "      # Loop through each line in the file  \n",
    "      for i, line in enumerate(fi):\n",
    "        # Check if it is the third line (index 2) in the file    \n",
    "        if i ==2:\n",
    "          words = line.split()\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            # Loop through the dictionary to find the corresponding word index\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                # Update the features matrix with word counts\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      # Assign a label of 0 (non-spam) by default          \n",
    "      train_labels[docID] = 0;\n",
    "      # Extract the last token from the file path\n",
    "      filepathTokens = fil.split('/')\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      # If the last token starts with \"spmsg\", assign a label of 1 (spam)  \n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoq-rE7Mx0pp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the paths for the training and testing datasets\n",
    "TRAIN_DIR = 'Data/train-mails'\n",
    "TEST_DIR = 'Data/test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "# Extract features for both training and testing datasets\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algorithm .....\n",
      "Training completed\n",
      "Testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "Accuracy Score: 0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the Naive Bayes model\n",
    "def train_and_evaluate(features_matrix, labels, test_features_matrix, test_labels):\n",
    "    # Initialize Gaussian Naive Bayes model\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Train the model using the training data\n",
    "    print(\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
    "    model.fit(features_matrix, labels)\n",
    "    print(\"Training completed\")\n",
    "\n",
    "    # Predict labels for the test data\n",
    "    print(\"Testing trained model to predict Test Data labels\")\n",
    "    predicted_labels = model.predict(test_features_matrix)\n",
    "\n",
    "    # Evaluate performance\n",
    "    print(\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "train_and_evaluate(features_matrix, labels, test_features_matrix, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
